{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fe331e-1fea-426d-90ca-b54e8189dc51",
   "metadata": {},
   "source": [
    "## Pengambilan Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fcb4e1-4197-4e0f-bc37-5369cad564c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n",
      "Tweets terambil: 100.\n",
      "\n",
      "5 tweet teratas:\n",
      "\n",
      "@laaaanis wkkwkw tengkiuuu\n",
      "\n",
      "Kamu yang salah, kok kamu yang marah\n",
      "\n",
      "Hari ini ke Lotte World Korea, pake seragam sekolah Korea wkwkwk. Seruuu bgt! Tungguin vlog Korea Trip yahh! https://t.co/CmszdIGiSc\n",
      "\n",
      "@jehianps @samsungID Thx ingfo\n",
      "\n",
      "RT @kamubukanakuu: PERKARA JAMBU JD PANJANG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import tweepy\n",
    "import numpy as np\n",
    "\n",
    "def twitter_config():\n",
    "    \"\"\"\n",
    "    Fungsi utilitas untuk mengkonfigurasi konsumsi file API Twitter dengan‚ê£\n",
    "    ,!kunci yang disediakan.\n",
    "    \"\"\"\n",
    "    # Otentikasi dan akses menggunakan kunci:\n",
    "    auth = tweepy.OAuthHandler(\"2fqCjSqwb2Thb9jgW8s1gXBq3\",\n",
    "    \"4qEqrnvomA4S6zwSI3C27KZ8OHJshwK13gikJom64hfTrHdhAT\")\n",
    "    auth.set_access_token(\"1569924724393938945-kCcwLjcnELsFyzTk7fN4zCmpKsDnad\",\n",
    "    \"0QOR6BDWt0Pwc16zGID27JObvzLzn7RW4vjeujMAqP0Fz\")\n",
    "    # Kembalikan akses ke API:\n",
    "    api = tweepy.API(auth)\n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "        print(\"Authentication OK\")\n",
    "    except:\n",
    "        print(\"Error during authentication\")\n",
    "    return api\n",
    "\n",
    "# buat extractor object\n",
    "extractor = twitter_config()\n",
    "\n",
    "\n",
    "tweets = extractor.user_timeline(screen_name=\"JeromePolin\", count=100)\n",
    "print(\"Tweets terambil: {}.\\n\".format(len(tweets)))\n",
    "\n",
    "\n",
    "print(\"5 tweet teratas:\\n\")\n",
    "for tweet in tweets[:5]:\n",
    "    print(tweet.text)\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d311ef94-c069-429c-b206-2460fbf89704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@laaaanis wkkwkw tengkiuuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kamu yang salah, kok kamu yang marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hari ini ke Lotte World Korea, pake seragam se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jehianps @samsungID Thx ingfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @kamubukanakuu: PERKARA JAMBU JD PANJANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @barkhohum: konspirasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @yxxxb_07: Masuk akal sih ü§£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @sminyeop: diluar nalar wkwkkw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Viral seorang anak ditanya ‚àö25 = ‚Ä¶? Dan anak t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bentar lagi bakal trip ke Korea, gak sabar ket...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0                         @laaaanis wkkwkw tengkiuuu\n",
       "1               Kamu yang salah, kok kamu yang marah\n",
       "2  Hari ini ke Lotte World Korea, pake seragam se...\n",
       "3                     @jehianps @samsungID Thx ingfo\n",
       "4        RT @kamubukanakuu: PERKARA JAMBU JD PANJANG\n",
       "5                          RT @barkhohum: konspirasi\n",
       "6                     RT @yxxxb_07: Masuk akal sih ü§£\n",
       "7                  RT @sminyeop: diluar nalar wkwkkw\n",
       "8  Viral seorang anak ditanya ‚àö25 = ‚Ä¶? Dan anak t...\n",
       "9  Bentar lagi bakal trip ke Korea, gak sabar ket..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Kita dapat membuat kerangka data sebagai berikut:\n",
    "dataset = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "# Kami membuat tampilan kerangka data:\n",
    "display(dataset.head(10))\n",
    "\n",
    "dataset.to_csv('Data Mentah Jerome.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9680b90-630c-4baa-bc21-6ca4a5771569",
   "metadata": {},
   "source": [
    "## Pengolahan Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a721d2e6-667c-40ba-81a3-b7b68918b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11a552-5204-4c4d-a165-7aa57c744cd3",
   "metadata": {},
   "source": [
    "## Membaca Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0784146d-91af-44e6-8c7f-61c54943a9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@laaaanis wkkwkw tengkiuuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kamu yang salah, kok kamu yang marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hari ini ke Lotte World Korea, pake seragam se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@jehianps @samsungID Thx ingfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @kamubukanakuu: PERKARA JAMBU JD PANJANG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Tweets\n",
       "0           0                         @laaaanis wkkwkw tengkiuuu\n",
       "1           1               Kamu yang salah, kok kamu yang marah\n",
       "2           2  Hari ini ke Lotte World Korea, pake seragam se...\n",
       "3           3                     @jehianps @samsungID Thx ingfo\n",
       "4           4        RT @kamubukanakuu: PERKARA JAMBU JD PANJANG"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data Mentah Jerome.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf8103-4bb5-4d90-89df-7e853681ea59",
   "metadata": {},
   "source": [
    "## Instalasi Package Ekpharasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc662e30-d6eb-4553-a583-8a1e8635c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ekphrasis\n",
      "  Downloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (3.6.1)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (4.59.0)\n",
      "Requirement already satisfied: ujson in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (4.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (3.3.4)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (0.4.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from ekphrasis) (1.20.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ftfy->ekphrasis) (0.2.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->ekphrasis) (8.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->ekphrasis) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->ekphrasis) (2021.4.4)\n",
      "Installing collected packages: termcolor, ftfy, ekphrasis\n",
      "Successfully installed ekphrasis-0.5.4 ftfy-6.1.1 termcolor-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e39b2b-0292-453b-9ad0-bac8a47ec5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    #annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",'emphasis', 'censored'},\n",
    "    annotate={\"hashtag\"},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce015456-220c-4bae-ab39-5bda2a88ffaf",
   "metadata": {},
   "source": [
    "## Membuat Fungsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e9c7591-a4ec-47be-95f8-4915d7498e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panggil ekphrasis\n",
    "\n",
    "def bersih_data(text):\n",
    "    return \" \".join(text_processor.pre_process_doc(text))\n",
    "# fungsi dari AMS 01-03. silakan cek bagaimana saya merubah menjadi fungsi\n",
    "\n",
    "def non_ascii(text):\n",
    "    return text.encode('ascii', 'replace').decode('ascii')\n",
    "\n",
    "def remove_space_alzami(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def remove_emoji_alzami(text):\n",
    "    return ' '.join(re.sub(\"([x#][A-Za-z0-9]+)\",\" \", text).split())\n",
    "\n",
    "def remove_tab(text):\n",
    "    return text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "\n",
    "def remove_tab2(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_rt(text):\n",
    "    return text.replace('RT',\" \")\n",
    "\n",
    "def remove_mention(text):\n",
    "    return ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "\n",
    "def remove_incomplete_url(text):\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def change_stripe(text):\n",
    "    return text.replace('-',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"_\", \"\") # don't remove hyphens\n",
    "    pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "    return re.sub(pattern, \"\", text) \n",
    "# hapus untuk <>\n",
    "def remove_number_eks(text):\n",
    "    return text.replace('<number>',\" \")\n",
    "\n",
    "def remove_angka(text):\n",
    "    return re.sub(r\"\\d+\", \"\", text) \n",
    "\n",
    "def remove_URL_eks(text):\n",
    "    return text.replace('URL',\" \").replace('url',\" \")\n",
    "\n",
    "def space_punctuation(text):\n",
    "    return re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb1910-831d-4f17-b6a1-66e176ea9bcf",
   "metadata": {},
   "source": [
    "## Memanggil Fungsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e11912-903d-420c-b1c1-12ad2b1f182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "final_string = []\n",
    "s = \"\"\n",
    "for text in df['Tweets'].values:\n",
    "    filteredSentence = []\n",
    "    EachReviewText = \"\"\n",
    "    proc = remove_rt(text)\n",
    "    proc = lower(proc)\n",
    "    proc = change_stripe(proc)\n",
    "    proc = remove_emoji_alzami(proc)\n",
    "    proc = remove_tab(proc)\n",
    "    proc = remove_tab2(proc)\n",
    "    proc = non_ascii(proc)\n",
    "    proc = remove_incomplete_url(proc)\n",
    "    proc = remove_excessive_dot(proc)\n",
    "    proc = remove_whitespace_LT(proc)\n",
    "    proc = remove_whitespace_multiple(proc)\n",
    "    proc = remove_single_char(proc)\n",
    "    proc = space_punctuation(proc)\n",
    "    proc = remove_punctuation(proc)\n",
    "    proc = remove_space_alzami(proc)\n",
    "    proc = bersih_data(proc)\n",
    "    proc = remove_number_eks(proc)\n",
    "    proc = remove_angka(proc) \n",
    "    proc = remove_URL_eks(proc)\n",
    "    EachReviewText = proc\n",
    "    final_string.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ad440d-2229-4ad8-ac05-35429ffbf1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@laaaanis wkkwkw tengkiuuu</td>\n",
       "      <td>laaaanis wkkwkw tengkiuuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kamu yang salah, kok kamu yang marah</td>\n",
       "      <td>kamu yang salah kok kamu yang marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hari ini ke Lotte World Korea, pake seragam se...</td>\n",
       "      <td>hari ini ke lotte world korea pake seragam sek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@jehianps @samsungID Thx ingfo</td>\n",
       "      <td>jehianps samsungid thx ingfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @kamubukanakuu: PERKARA JAMBU JD PANJANG</td>\n",
       "      <td>kamubukanakuu perkara jambu jd panjang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>RT @barkhohum: konspirasi</td>\n",
       "      <td>barkhohum konspirasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>RT @yxxxb_07: Masuk akal sih ü§£</td>\n",
       "      <td>_ masuk akal sih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>RT @sminyeop: diluar nalar wkwkkw</td>\n",
       "      <td>sminyeop diluar nalar wkwkkw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Viral seorang anak ditanya ‚àö25 = ‚Ä¶? Dan anak t...</td>\n",
       "      <td>viral seorang anak ditanya   dan anak tersebut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Bentar lagi bakal trip ke Korea, gak sabar ket...</td>\n",
       "      <td>bentar lagi bakal trip ke korea gak sabar kete...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Tweets  \\\n",
       "0           0                         @laaaanis wkkwkw tengkiuuu   \n",
       "1           1               Kamu yang salah, kok kamu yang marah   \n",
       "2           2  Hari ini ke Lotte World Korea, pake seragam se...   \n",
       "3           3                     @jehianps @samsungID Thx ingfo   \n",
       "4           4        RT @kamubukanakuu: PERKARA JAMBU JD PANJANG   \n",
       "5           5                          RT @barkhohum: konspirasi   \n",
       "6           6                     RT @yxxxb_07: Masuk akal sih ü§£   \n",
       "7           7                  RT @sminyeop: diluar nalar wkwkkw   \n",
       "8           8  Viral seorang anak ditanya ‚àö25 = ‚Ä¶? Dan anak t...   \n",
       "9           9  Bentar lagi bakal trip ke Korea, gak sabar ket...   \n",
       "\n",
       "                                              step01  \n",
       "0                          laaaanis wkkwkw tengkiuuu  \n",
       "1                kamu yang salah kok kamu yang marah  \n",
       "2  hari ini ke lotte world korea pake seragam sek...  \n",
       "3                       jehianps samsungid thx ingfo  \n",
       "4             kamubukanakuu perkara jambu jd panjang  \n",
       "5                               barkhohum konspirasi  \n",
       "6                                   _ masuk akal sih  \n",
       "7                       sminyeop diluar nalar wkwkkw  \n",
       "8  viral seorang anak ditanya   dan anak tersebut...  \n",
       "9  bentar lagi bakal trip ke korea gak sabar kete...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"step01\"] = final_string\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e543e-ba55-4d23-b84d-0371254116d0",
   "metadata": {},
   "source": [
    "## Menghapus Data yang kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f81f9e6-96f9-4637-9abe-8ff6234cf775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  100 non-null    int64 \n",
      " 1   Tweets      100 non-null    object\n",
      " 2   step01      100 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4 entries, 60 to 85\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4 non-null      int64 \n",
      " 1   Tweets      4 non-null      object\n",
      " 2   step01      4 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 128.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>Semangat!!</td>\n",
       "      <td>semangat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>ÂêõÔºåÈ†ëÂºµ„Å£„Å¶„Åè„Å†„Åï„ÅÑ!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>RT @nikone_25: ÂÆâÂÄçÂÖÉÁ∑èÁêÜ„Åå„Åä‰∫°„Åè„Å™„Çä„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇË®ÄËëâ„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇÁäØ‰∫∫„ÅåÊÜé...</td>\n",
       "      <td>nikone_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>semangat!!!!</td>\n",
       "      <td>semangat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                             Tweets    step01\n",
       "60          60                                         Semangat!!  semangat\n",
       "71          71                                        ÂêõÔºåÈ†ëÂºµ„Å£„Å¶„Åè„Å†„Åï„ÅÑ!          \n",
       "72          72  RT @nikone_25: ÂÆâÂÄçÂÖÉÁ∑èÁêÜ„Åå„Åä‰∫°„Åè„Å™„Çä„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇË®ÄËëâ„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇÁäØ‰∫∫„ÅåÊÜé...   nikone_\n",
       "85          85                                       semangat!!!!  semangat"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df_hapus = df[~df['step01'].str.contains(\" \")]\n",
    "df_hapus.info()\n",
    "df_hapus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f472abe-3baf-45bf-acff-d3c0fd59e910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  96 non-null     float64\n",
      " 1   Tweets      96 non-null     object \n",
      " 2   step01      96 non-null     object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 3.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@laaaanis wkkwkw tengkiuuu</td>\n",
       "      <td>laaaanis wkkwkw tengkiuuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Kamu yang salah, kok kamu yang marah</td>\n",
       "      <td>kamu yang salah kok kamu yang marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Hari ini ke Lotte World Korea, pake seragam se...</td>\n",
       "      <td>hari ini ke lotte world korea pake seragam sek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>@jehianps @samsungID Thx ingfo</td>\n",
       "      <td>jehianps samsungid thx ingfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RT @kamubukanakuu: PERKARA JAMBU JD PANJANG</td>\n",
       "      <td>kamubukanakuu perkara jambu jd panjang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95.0</td>\n",
       "      <td>Heran kenapa banyak orang suka ngomongin orang...</td>\n",
       "      <td>heran kenapa banyak orang suka ngomongin orang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>@ViktorAxelsen halo</td>\n",
       "      <td>viktora halo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>viktor pasti takut lawan kucing gemuk</td>\n",
       "      <td>viktor pasti takut lawan kucing gemuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>Latian buat main lawan viktor axelsen WKWKWKWK...</td>\n",
       "      <td>latian buat main lawan viktor wkwkwkwk cofobgqpo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>SEMANGAT YOKKK JGN LEMES LEMES GITU DONG</td>\n",
       "      <td>semangat yokkk jgn lemes lemes gitu dong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                             Tweets  \\\n",
       "0          0.0                         @laaaanis wkkwkw tengkiuuu   \n",
       "1          1.0               Kamu yang salah, kok kamu yang marah   \n",
       "2          2.0  Hari ini ke Lotte World Korea, pake seragam se...   \n",
       "3          3.0                     @jehianps @samsungID Thx ingfo   \n",
       "4          4.0        RT @kamubukanakuu: PERKARA JAMBU JD PANJANG   \n",
       "..         ...                                                ...   \n",
       "95        95.0  Heran kenapa banyak orang suka ngomongin orang...   \n",
       "96        96.0                                @ViktorAxelsen halo   \n",
       "97        97.0              viktor pasti takut lawan kucing gemuk   \n",
       "98        98.0  Latian buat main lawan viktor axelsen WKWKWKWK...   \n",
       "99        99.0           SEMANGAT YOKKK JGN LEMES LEMES GITU DONG   \n",
       "\n",
       "                                               step01  \n",
       "0                           laaaanis wkkwkw tengkiuuu  \n",
       "1                 kamu yang salah kok kamu yang marah  \n",
       "2   hari ini ke lotte world korea pake seragam sek...  \n",
       "3                        jehianps samsungid thx ingfo  \n",
       "4              kamubukanakuu perkara jambu jd panjang  \n",
       "..                                                ...  \n",
       "95  heran kenapa banyak orang suka ngomongin orang...  \n",
       "96                                       viktora halo  \n",
       "97              viktor pasti takut lawan kucing gemuk  \n",
       "98   latian buat main lawan viktor wkwkwkwk cofobgqpo  \n",
       "99           semangat yokkk jgn lemes lemes gitu dong  \n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df[~df.isin(df_hapus)].dropna()\n",
    "df_new.info()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a12fb-1638-46cf-88f5-d27488a2b045",
   "metadata": {},
   "source": [
    "## Normalisasi Kata Slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8982ec0-d459-4b96-bd42-d36b8156bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "226b7557-ad7e-4dc6-a106-194669dd497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize_wrapper(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb714e2-424d-4400-aed2-03185e3b45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['tokens'] = df['step01'].apply(word_tokenize_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7272cd14-f186-418b-b886-bb8dfdaee41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@laaaanis wkkwkw tengkiuuu</td>\n",
       "      <td>laaaanis wkkwkw tengkiuuu</td>\n",
       "      <td>[laaaanis, wkkwkw, tengkiuuu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Kamu yang salah, kok kamu yang marah</td>\n",
       "      <td>kamu yang salah kok kamu yang marah</td>\n",
       "      <td>[kamu, yang, salah, kok, kamu, yang, marah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Hari ini ke Lotte World Korea, pake seragam se...</td>\n",
       "      <td>hari ini ke lotte world korea pake seragam sek...</td>\n",
       "      <td>[hari, ini, ke, lotte, world, korea, pake, ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>@jehianps @samsungID Thx ingfo</td>\n",
       "      <td>jehianps samsungid thx ingfo</td>\n",
       "      <td>[jehianps, samsungid, thx, ingfo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RT @kamubukanakuu: PERKARA JAMBU JD PANJANG</td>\n",
       "      <td>kamubukanakuu perkara jambu jd panjang</td>\n",
       "      <td>[kamubukanakuu, perkara, jambu, jd, panjang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>RT @barkhohum: konspirasi</td>\n",
       "      <td>barkhohum konspirasi</td>\n",
       "      <td>[barkhohum, konspirasi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>RT @yxxxb_07: Masuk akal sih ü§£</td>\n",
       "      <td>_ masuk akal sih</td>\n",
       "      <td>[_, masuk, akal, sih]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>RT @sminyeop: diluar nalar wkwkkw</td>\n",
       "      <td>sminyeop diluar nalar wkwkkw</td>\n",
       "      <td>[sminyeop, diluar, nalar, wkwkkw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Viral seorang anak ditanya ‚àö25 = ‚Ä¶? Dan anak t...</td>\n",
       "      <td>viral seorang anak ditanya   dan anak tersebut...</td>\n",
       "      <td>[viral, seorang, anak, ditanya, dan, anak, ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Bentar lagi bakal trip ke Korea, gak sabar ket...</td>\n",
       "      <td>bentar lagi bakal trip ke korea gak sabar kete...</td>\n",
       "      <td>[bentar, lagi, bakal, trip, ke, korea, gak, sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Tweets  \\\n",
       "0         0.0                         @laaaanis wkkwkw tengkiuuu   \n",
       "1         1.0               Kamu yang salah, kok kamu yang marah   \n",
       "2         2.0  Hari ini ke Lotte World Korea, pake seragam se...   \n",
       "3         3.0                     @jehianps @samsungID Thx ingfo   \n",
       "4         4.0        RT @kamubukanakuu: PERKARA JAMBU JD PANJANG   \n",
       "5         5.0                          RT @barkhohum: konspirasi   \n",
       "6         6.0                     RT @yxxxb_07: Masuk akal sih ü§£   \n",
       "7         7.0                  RT @sminyeop: diluar nalar wkwkkw   \n",
       "8         8.0  Viral seorang anak ditanya ‚àö25 = ‚Ä¶? Dan anak t...   \n",
       "9         9.0  Bentar lagi bakal trip ke Korea, gak sabar ket...   \n",
       "\n",
       "                                              step01  \\\n",
       "0                          laaaanis wkkwkw tengkiuuu   \n",
       "1                kamu yang salah kok kamu yang marah   \n",
       "2  hari ini ke lotte world korea pake seragam sek...   \n",
       "3                       jehianps samsungid thx ingfo   \n",
       "4             kamubukanakuu perkara jambu jd panjang   \n",
       "5                               barkhohum konspirasi   \n",
       "6                                   _ masuk akal sih   \n",
       "7                       sminyeop diluar nalar wkwkkw   \n",
       "8  viral seorang anak ditanya   dan anak tersebut...   \n",
       "9  bentar lagi bakal trip ke korea gak sabar kete...   \n",
       "\n",
       "                                              tokens  \n",
       "0                      [laaaanis, wkkwkw, tengkiuuu]  \n",
       "1        [kamu, yang, salah, kok, kamu, yang, marah]  \n",
       "2  [hari, ini, ke, lotte, world, korea, pake, ser...  \n",
       "3                  [jehianps, samsungid, thx, ingfo]  \n",
       "4       [kamubukanakuu, perkara, jambu, jd, panjang]  \n",
       "5                            [barkhohum, konspirasi]  \n",
       "6                              [_, masuk, akal, sih]  \n",
       "7                  [sminyeop, diluar, nalar, wkwkkw]  \n",
       "8  [viral, seorang, anak, ditanya, dan, anak, ter...  \n",
       "9  [bentar, lagi, bakal, trip, ke, korea, gak, sa...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4372051-aaf8-47f7-ab87-f22776dfefb9",
   "metadata": {},
   "source": [
    "## Clean Kamus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd1ff9f-caa3-4783-96c8-f60ab10a42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_word = pd.read_csv('kamus_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b43ec706-599a-42a2-beda-881663ce1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_word_dict = {}\n",
    "\n",
    "for index, row in normalized_word.iterrows():\n",
    "    if row[0] not in normalized_word_dict:\n",
    "        normalized_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalized_word_dict[term] if term in normalized_word_dict else term for term in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00aff417-181e-4ba0-9609-db8e1d7e3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['final_tokens'] = df_new['tokens'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76eea6fb-e69e-49ff-ba14-aad43743e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "final_string_tokens = []\n",
    "for text in df_new['final_tokens'].values:\n",
    "    EachReviewText = \"\"\n",
    "    EachReviewText = ' '.join(text)\n",
    "    final_string_tokens.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606fd3ad-6a9e-4a82-a8a1-6c9d2715cea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_tokens</th>\n",
       "      <th>step02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@laaaanis wkkwkw tengkiuuu</td>\n",
       "      <td>laaaanis wkkwkw tengkiuuu</td>\n",
       "      <td>[laaaanis, wkkwkw, tengkiuuu]</td>\n",
       "      <td>[laaaanis, wkkwkw, tengkiuuu]</td>\n",
       "      <td>laaaanis wkkwkw tengkiuuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Kamu yang salah, kok kamu yang marah</td>\n",
       "      <td>kamu yang salah kok kamu yang marah</td>\n",
       "      <td>[kamu, yang, salah, kok, kamu, yang, marah]</td>\n",
       "      <td>[kamu, yang, salah, kok, kamu, yang, marah]</td>\n",
       "      <td>kamu yang salah kok kamu yang marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Hari ini ke Lotte World Korea, pake seragam se...</td>\n",
       "      <td>hari ini ke lotte world korea pake seragam sek...</td>\n",
       "      <td>[hari, ini, ke, lotte, world, korea, pake, ser...</td>\n",
       "      <td>[hari, ini, ke, lotte, world, korea, pake, ser...</td>\n",
       "      <td>hari ini ke lotte world korea pake seragam sek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>@jehianps @samsungID Thx ingfo</td>\n",
       "      <td>jehianps samsungid thx ingfo</td>\n",
       "      <td>[jehianps, samsungid, thx, ingfo]</td>\n",
       "      <td>[jehianps, samsungid, thx, ingfo]</td>\n",
       "      <td>jehianps samsungid thx ingfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RT @kamubukanakuu: PERKARA JAMBU JD PANJANG</td>\n",
       "      <td>kamubukanakuu perkara jambu jd panjang</td>\n",
       "      <td>[kamubukanakuu, perkara, jambu, jd, panjang]</td>\n",
       "      <td>[kamubukanakuu, perkara, jambu, jd, panjang]</td>\n",
       "      <td>kamubukanakuu perkara jambu jd panjang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>RT @barkhohum: konspirasi</td>\n",
       "      <td>barkhohum konspirasi</td>\n",
       "      <td>[barkhohum, konspirasi]</td>\n",
       "      <td>[barkhohum, konspirasi]</td>\n",
       "      <td>barkhohum konspirasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>RT @yxxxb_07: Masuk akal sih ü§£</td>\n",
       "      <td>_ masuk akal sih</td>\n",
       "      <td>[_, masuk, akal, sih]</td>\n",
       "      <td>[_, masuk, akal, sih]</td>\n",
       "      <td>_ masuk akal sih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>RT @sminyeop: diluar nalar wkwkkw</td>\n",
       "      <td>sminyeop diluar nalar wkwkkw</td>\n",
       "      <td>[sminyeop, diluar, nalar, wkwkkw]</td>\n",
       "      <td>[sminyeop, diluar, nalar, wkwkkw]</td>\n",
       "      <td>sminyeop diluar nalar wkwkkw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Viral seorang anak ditanya ‚àö25 = ‚Ä¶? Dan anak t...</td>\n",
       "      <td>viral seorang anak ditanya   dan anak tersebut...</td>\n",
       "      <td>[viral, seorang, anak, ditanya, dan, anak, ter...</td>\n",
       "      <td>[viral, seorang, anak, ditanya, dan, anak, ter...</td>\n",
       "      <td>viral seorang anak ditanya dan anak tersebut m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Bentar lagi bakal trip ke Korea, gak sabar ket...</td>\n",
       "      <td>bentar lagi bakal trip ke korea gak sabar kete...</td>\n",
       "      <td>[bentar, lagi, bakal, trip, ke, korea, gak, sa...</td>\n",
       "      <td>[bentar, lagi, bakal, trip, ke, korea, gak, sa...</td>\n",
       "      <td>bentar lagi bakal trip ke korea gak sabar kete...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Tweets  \\\n",
       "0         0.0                         @laaaanis wkkwkw tengkiuuu   \n",
       "1         1.0               Kamu yang salah, kok kamu yang marah   \n",
       "2         2.0  Hari ini ke Lotte World Korea, pake seragam se...   \n",
       "3         3.0                     @jehianps @samsungID Thx ingfo   \n",
       "4         4.0        RT @kamubukanakuu: PERKARA JAMBU JD PANJANG   \n",
       "5         5.0                          RT @barkhohum: konspirasi   \n",
       "6         6.0                     RT @yxxxb_07: Masuk akal sih ü§£   \n",
       "7         7.0                  RT @sminyeop: diluar nalar wkwkkw   \n",
       "8         8.0  Viral seorang anak ditanya ‚àö25 = ‚Ä¶? Dan anak t...   \n",
       "9         9.0  Bentar lagi bakal trip ke Korea, gak sabar ket...   \n",
       "\n",
       "                                              step01  \\\n",
       "0                          laaaanis wkkwkw tengkiuuu   \n",
       "1                kamu yang salah kok kamu yang marah   \n",
       "2  hari ini ke lotte world korea pake seragam sek...   \n",
       "3                       jehianps samsungid thx ingfo   \n",
       "4             kamubukanakuu perkara jambu jd panjang   \n",
       "5                               barkhohum konspirasi   \n",
       "6                                   _ masuk akal sih   \n",
       "7                       sminyeop diluar nalar wkwkkw   \n",
       "8  viral seorang anak ditanya   dan anak tersebut...   \n",
       "9  bentar lagi bakal trip ke korea gak sabar kete...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                      [laaaanis, wkkwkw, tengkiuuu]   \n",
       "1        [kamu, yang, salah, kok, kamu, yang, marah]   \n",
       "2  [hari, ini, ke, lotte, world, korea, pake, ser...   \n",
       "3                  [jehianps, samsungid, thx, ingfo]   \n",
       "4       [kamubukanakuu, perkara, jambu, jd, panjang]   \n",
       "5                            [barkhohum, konspirasi]   \n",
       "6                              [_, masuk, akal, sih]   \n",
       "7                  [sminyeop, diluar, nalar, wkwkkw]   \n",
       "8  [viral, seorang, anak, ditanya, dan, anak, ter...   \n",
       "9  [bentar, lagi, bakal, trip, ke, korea, gak, sa...   \n",
       "\n",
       "                                        final_tokens  \\\n",
       "0                      [laaaanis, wkkwkw, tengkiuuu]   \n",
       "1        [kamu, yang, salah, kok, kamu, yang, marah]   \n",
       "2  [hari, ini, ke, lotte, world, korea, pake, ser...   \n",
       "3                  [jehianps, samsungid, thx, ingfo]   \n",
       "4       [kamubukanakuu, perkara, jambu, jd, panjang]   \n",
       "5                            [barkhohum, konspirasi]   \n",
       "6                              [_, masuk, akal, sih]   \n",
       "7                  [sminyeop, diluar, nalar, wkwkkw]   \n",
       "8  [viral, seorang, anak, ditanya, dan, anak, ter...   \n",
       "9  [bentar, lagi, bakal, trip, ke, korea, gak, sa...   \n",
       "\n",
       "                                              step02  \n",
       "0                          laaaanis wkkwkw tengkiuuu  \n",
       "1                kamu yang salah kok kamu yang marah  \n",
       "2  hari ini ke lotte world korea pake seragam sek...  \n",
       "3                       jehianps samsungid thx ingfo  \n",
       "4             kamubukanakuu perkara jambu jd panjang  \n",
       "5                               barkhohum konspirasi  \n",
       "6                                   _ masuk akal sih  \n",
       "7                       sminyeop diluar nalar wkwkkw  \n",
       "8  viral seorang anak ditanya dan anak tersebut m...  \n",
       "9  bentar lagi bakal trip ke korea gak sabar kete...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"step02\"] = final_string_tokens\n",
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "485ad6fd-c9b7-4bde-ab1f-0fafa52c8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('Data Set Bersih.csv',sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
